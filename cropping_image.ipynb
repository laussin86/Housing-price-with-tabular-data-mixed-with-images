{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip  install opencv-python\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the list of images in the folder\n",
    "folder_path = 'C:\\\\Users\\\\lauss\\\\Desktop\\\\web scrapping images\\\\Houses'\n",
    "list_of_original_images = os.listdir(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in list_of_original_images:\n",
    "    image_path = os.path.join(folder_path, img)\n",
    "    images = cv.imread(image_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image (230, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the input image\n",
    "print(\"Shape of the image\", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load image: house99.jpg\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the image_list\n",
    "for image_filename in list_of_original_images:\n",
    "    image_path = os.path.join(folder_path, image_filename)  # Get the full path to the image file\n",
    "    image_array = cv.imread(image_path)  # Load the image using OpenCV\n",
    "    if image_array is not None:  # Check if the image was loaded successfully\n",
    "        info = np.iinfo(image_array.dtype) # Get the information of the incoming image type\n",
    "        image_array = image_array.astype(np.float64) / info.max # normalize the data to 0 - 1\n",
    "        image_array = 255 * image_array # Now scale by 255\n",
    "        image_array = image_array.astype(np.uint8)\n",
    "        ## (1) Convert to gray, and threshold\n",
    "        gray = cv.cvtColor(image_array, cv.COLOR_BGR2GRAY)\n",
    "        th, threshed = cv.threshold(gray, 120, 255, cv.THRESH_BINARY_INV)\n",
    "        \n",
    "        ## (2) Morph-op to remove noise\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (11,11))\n",
    "        morphed = cv.morphologyEx(threshed, cv.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        ## (3) Find contours\n",
    "        contours, hierarchy = cv.findContours(morphed, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        xmin=[]\n",
    "        xmax=[]\n",
    "        ymin=[]\n",
    "        ymax=[]\n",
    "        for c in contours:\n",
    "            x,y,w,h = cv.boundingRect(c)\n",
    "            xmin.append(x)\n",
    "            xmax.append(x+w)\n",
    "            ymin.append(y)\n",
    "            ymax.append(y+h)\n",
    "            \n",
    "        xmin=min(xmin)\n",
    "        xmax=max(xmax)\n",
    "        ymin=min(ymin)\n",
    "        ymax=max(ymax)\n",
    "        cv.rectangle(image_array, (xmin, ymin), (xmax, ymax), (0,0,0), 2)\n",
    "        dst = image_array[ymin:ymax, xmin:xmax]\n",
    "        ## (4) putting cropped images in a new folder\n",
    "        cropped_image_path = os.path.join('C:\\\\Users\\\\lauss\\\\Desktop\\\\web scrapping images\\\\Cropped_Houses', 'cropped_' + image_filename)\n",
    "        cv.imwrite(cropped_image_path, dst)\n",
    "else:\n",
    "        print(f\"Could not load image: {image_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
